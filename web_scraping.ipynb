{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "web-scraping.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyME8OoSwNQofSfBCWoO+G7b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pauloigorms/web-scraping-olx/blob/main/web_scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT5XUNQte75S"
      },
      "source": [
        "<p><img alt=\"Ãcone importando do portal FlatIcon\" width=\"30\" src=\"https://www.flaticon.com/svg/static/icons/svg/2742/2742225.svg\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "<h1><strong>Web Scraping | OLX E-commerce</strong></h1>\n",
        "\n",
        "&emsp; Projeto independente sem fins lucrativos apenas com intuito de acrescentar e fixar conhecimentos em <b>web scraping</b>.\n",
        "\n",
        "\n",
        "<br />\n",
        "\n",
        "<i>Por Paulo Igor Moraes</i>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuGgYdkYekx4"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import Request, urlopen\n",
        "import pandas as pd\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoSu5y38lFlq"
      },
      "source": [
        "def getDataOLX(pages = 2):\n",
        "\n",
        "  params = {\n",
        "    'authority': 'am.olx.com.br',\n",
        "    'methoid': 'GET',\n",
        "    'scheme': 'https',\n",
        "    'user-agent': 'Mozilla/5.0'\n",
        "  }\n",
        "\n",
        "  for x in range(1, pages):\n",
        "\n",
        "    page_result = Request(url_based + str(x), headers = params)\n",
        "    page_parser = BeautifulSoup(urlopen(page_result).read(), 'html.parser')\n",
        "    items = page_parser.find('div', {'class': 'sc-1fcmfeb-0'}).find_all('li')\n",
        "\n",
        "    for item in items:\n",
        "\n",
        "      content = item.find('a')\n",
        "\n",
        "      if (content):\n",
        "        try:\n",
        "          \n",
        "          price = content.find('div', {'class': 'fnmrjs-9'}).find('span').get_text()\n",
        "          if (price):\n",
        "            price = price.split('R$')[1]\n",
        "            price = float(price.replace(\".\",\"\"))\n",
        "          else:\n",
        "            price = 0\n",
        "\n",
        "          link = content.get('href')\n",
        "          \n",
        "          data = {\n",
        "            'id': content.get('data-lurker_list_id'),\n",
        "            'link': link,\n",
        "            'text': content.find('h2').get_text(),\n",
        "            'image_home': content.find('img')['src'],\n",
        "            'image_alt': content.find('img')['alt'],\n",
        "            'price': price\n",
        "          }\n",
        "        \n",
        "          if (link):\n",
        "            item_page = Request(link, headers = params)\n",
        "            item_parser = BeautifulSoup(urlopen(item_page).read(), 'html.parser')\n",
        "            item_content = item_parser.find('div', {'class': 'duvuxf-0 h3us20-0 jAHFXn'})\n",
        "\n",
        "            description = item_content.find('span', { 'class': 'sc-1sj3nln-1 eOSweo sc-ifAKCX cmFKIN' }).get_text()\n",
        "\n",
        "            details = {}\n",
        "            items_details = item_content.find('div', {'data-testid': 'ad-properties'}).find_all('div', {'class':'sc-hmzhuo'})\n",
        "            for item in items_details:\n",
        "              elements = item.find_all()\n",
        "              if (elements[0].get_text() == 'Tamanho'):\n",
        "                details[elements[0].get_text()] = elements[1].get_text().split(\"m\")[0]\n",
        "              else:\n",
        "                details[elements[0].get_text()] = elements[1].get_text()\n",
        "              json.dumps(details)\n",
        "\n",
        "            data['details'] = details\n",
        "            json.dumps(data)\n",
        "            results.append(data)\n",
        "\n",
        "          else:\n",
        "            results.append(data)\n",
        "\n",
        "        except:\n",
        "          break\n",
        "      else:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf2vnh0eLE2N"
      },
      "source": [
        "declaredVariable()\n",
        "getDataOLX(pages = 2)\n",
        "pd.json_normalize(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWJE_1NU8FCV"
      },
      "source": [
        "def declaredVariable():\n",
        "  url_based = 'https://am.olx.com.br/regiao-de-manaus/imoveis?o='\n",
        "  results = []"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}